#speak fn backup


from selenium import webdriver
from selenium.webdriver.support.ui import Select
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from time import sleep

chrome_options = Options()
chrome_options.add_argument('--log-level=3')
chrome_options.headless = True
Path = "C:\\Users\\Jarvis... Mark85\\Desktop\\AI Jarvis\\DataBase\\chromedriver.exe"
driver = webdriver.Chrome(Path,options=chrome_options)
driver.maximize_window()

website = r"https://ttsmp3.com/text-to-speech/British%20English/"
driver.get(website)
ButtonSelection = Select(driver.find_element(by=By.XPATH,value='/html/body/div[4]/div[2]/form/select'))
ButtonSelection.select_by_visible_text('British English / Brian')

def Speak(Text):

    lengthoftext = len(str(Text))

    if lengthoftext==0:
        pass

    else:
        print("")
        print(f"AI : {Text}.")
        print("")
        Data = str(Text)
        xpathofsec = '/html/body/div[4]/div[2]/form/textarea'
        driver.find_element(By.XPATH,value=xpathofsec).send_keys(Data)
        driver.find_element(By.XPATH,value='//*[@id="vorlesenbutton"]').click()
        driver.find_element(By.XPATH,value="/html/body/div[4]/div[2]/form/textarea").clear()

        if lengthoftext>=30:
            sleep(4)

        elif lengthoftext>=40:
            sleep(6)

        elif lengthoftext>=55:
            sleep(8)

        elif lengthoftext>=70:
            sleep(10)

        elif lengthoftext>=100:
            sleep(13)

        elif lengthoftext>=120:
            sleep(14)

        else:
            sleep(2)


#listen fn backup

import speech_recognition as sr #pip install speechrecognition
from googletrans import Translator #pip install googletrans==3.1.0a0

# 1 - Listen : Hindi or English

def Listen():

    r = sr.Recognizer()

    with sr.Microphone() as source:
        print("Listening...")
        r.pause_threshold = 1
        audio = r.listen(source,0,8) # Listening Mode.....
    
    try:
        print("Recognizing...")
        query = r.recognize_google(audio,language="hi")

    except:
        return ""
    
    query = str(query).lower()
    return query

# 2 - Translation

def TranslationHinToEng(Text):
    line = str(Text)
    translate = Translator()
    result = translate.translate(line)
    data = result.text
    print(f"You : {data}.")
    return data

# 3 - Connect

def MicExecution():
    query = Listen()
    data = TranslationHinToEng(query)
    return data



import os
import pygame

voice2 = 'en-US-AnaNeural'
def Speak(data):
    #voice = 'en-US-SteffanNeural'
    command = f'edge-tts --voice "{voice2}" --text "{data}" --write-media "data.mp3"'
    os.system(command)

    pygame.init()
    pygame.mixer.init()
    pygame.mixer.music.load("data.mp3")

    try:
        pygame.mixer.music.play()

        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)

    except Exception as e:
        print(e)
    finally:
        pygame.mixer.music.stop()
        pygame.mixer.quit()















 brain backup




 import os
import re
import sys
from sydney import SydneyClient
from gtts import gTTS
import pygame
import sys
sys.path.append("C:\\Users\\srija\\Desktop\\AIJarvisl\\")
from Listen import MicExecution

os.environ["BING_U_COOKIE"] = "1AmnFYKNto-iLEOlsxWdXiA18SKyMdnJhXtBKPHckFcUlKULAOECoRqfSRsN732Rxuogz3nArbcJTBtz8jfgKN8hH1QTtWdzWdjntek4IJykAAVgVOAZDTJvyqFfp3gKVw0_mvljdJXwO2K88i1EssN10WuxX1MeQb98TjPSxqh7Zp3RroyVYADuAeyoGpH4-itqPguglTrSxe4le-m2VsdkKz3Q19ZETZfslcWznHQg"

def filter_response(response):
    # Remove markdown formatting characters
    response = re.sub(r'\*{1,3}', '', response)
    response = re.sub(r'\[[^\]]*\]\(\^[0-9]+\^\)', '', response)
    response = re.sub(r'\^[0-9]+\^', '', response)
    response = response.replace('[', '').replace(']', '')
    
    # Remove emojis
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           "]+", flags=re.UNICODE)
    response = emoji_pattern.sub(r'', response)
    

    return response


def txt_to_mp3(txt_file, mp3_file):
    with open(txt_file, 'r') as file:
        text = file.read()
    tts = gTTS(text=text, lang='en')
    tts.save(mp3_file)
      # Play the mp3 file using pygame
    pygame.mixer.init()
    pygame.mixer.music.load(mp3_file)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
       pygame.time.Clock().tick(10)


async def brainy() -> None:
    
    async with SydneyClient() as sydney:
        
        # Open the chat log file in append mode
        with open("DataBase\\chat_log.txt", "a",encoding='utf-8') as chat_log:
            
        
            print("You: ")
            prompt = MicExecution()
            chat_log.write(f"You: {prompt}\n")
            chat_log.flush()

            if prompt == "reset and make it creative":
                await sydney.reset_conversation(style="creative")
                

            if prompt == "reset and make it precise":
                await sydney.reset_conversation(style="precise")
                

            if prompt == "reset and make it balanced":
                await sydney.reset_conversation(style="balanced")
                


            elif prompt == "exit":
                sys.exit()
             

                
            print("Jarvis: ", end="", flush=True)
            response_text = ''
            async for response in sydney.ask_stream(prompt):
                print(response, end="", flush=True)
                chat_log.write(f"Jarvis: {response}\n")
                chat_log.flush()
                response_text += response
            print("\n")

            # Filter the response text
            filtered_response_text = filter_response(response_text)
            print (filtered_response_text)

            # Store the filtered response in a separate text file
            with open('speaking.txt', 'w', encoding='utf-8') as f:
                f.write(filtered_response_text)
            if filtered_response_text:
              txt_to_mp3('speaking.txt', 'output.mp3')
            
            # Speak the contents of the text file